```@meta
DocTestSetup = quote
    using HTM
end
```

# How does it work

Under the hood, HTM.jl mimicks
[observablehq/htl](https://observablehq.com/@observablehq/htl) by implementing
a subset of the HTML5 tokenizer state machine (TODO link to HTML5
specification).
This allows HTM.jl to distinguish different contexts such as tags and
attributes, allowing embedded expressions to be interpreted correctly.
This is more formal (and more precise) than using regular expressions to
search for "attribute-like sequences" in markup.
And while our approach requires scanning the input, the state machine is
pretty fast.

Better yet, the parsing happens at compile time, so there's almost no
overhead when comparing with e.g. using Hyperscript.jl directly:

```julia-repl
julia> using BenchmarkTools

julia> @btime htm"<span />"
  273.394 ns (8 allocations: 880 bytes)
<span></span>

julia> using Hyperscript

julia> @btime m("span")
  249.731 ns (7 allocations: 800 bytes)
<span></span>
```

The actual parsing happens at compile time, and the code generated by the
macro actually builds a complete tree.

```jldoctest
julia> @macroexpand htm"<span />"
:(create_element("span", (), ()))
```

The parsing processing is actually fast too:

```julia-repl
julia> using BenchmarkTools  # hide

julia> @btime HTM.parse("<span />");
  800.222 ns (24 allocations: 1.19 KiB)
```

And unlike regular string interpolation, HTM.jl directly creates content rather than reusable templates.
HTM.jl is thus well-suited to reactive environments, where HTML is automatically generated when inputs change.

We also wanted to minimize new syntax.
We were inspired by HTM, but HTM emulates JSX--not HTML5--requiring closing tags for every element.

For a closer look at our implementation, please [view the source](https://github.com/schneiderfelipe/HTM.jl) and let us know what you think! We welcome your contributions and bug reports on GitHub.
