```@meta
DocTestSetup = quote
    using HTM
end
```

# How does it work

HTM.jl follows [Hypertext Literal](https://github.com/observablehq/htl)
by implementing a subset of the
[HTML5 tokenizer state machine](https://html.spec.whatwg.org/multipage/parsing.html#tokenization)
(as well as a subset of the
[JSX draft specification](http://facebook.github.io/jsx/)).
This allows it to distinguish different contexts such as tags and
attributes, allowing embedded expressions to be interpreted correctly.
Unlike regular string interpolation, HTM.jl directly creates content rather
than reusable templates.

I also wanted to minimize new syntax.
The main inspiration was [`htm`](https://github.com/developit/htm) and, like
`htm`, HTM.jl attempts to emulate JSX--not quite HTML5--requiring closing tags
for every element.

Parsing happens at compile time and code generated by the macro builds an
element tree:

```jldoctest
julia> @macroexpand htm"<span />"
:((HTM.create_element)((HTM.create_tag)("span"), Pair{Symbol, Any}[], Any[]))
```

The overhead is small when compared to using Hyperscript.jl directly:

```julia-repl
julia> using BenchmarkTools

julia> @btime htm"<span />"
  273.394 ns (8 allocations: 880 bytes)
<span></span>

julia> using Hyperscript

julia> @btime m("span")
  249.731 ns (7 allocations: 800 bytes)
<span></span>
```

But parsing is quite fast too:

```julia-repl
julia> using BenchmarkTools  # hide

julia> @btime HTM.parse("<span />");
  800.222 ns (24 allocations: 1.19 KiB)
```

This approach requires scanning the input, but the state machine is
reasonably fast (see [Benchmarks](@ref) for a more complete comparison,
including memory usage).

For a closer look at the implementation, please
[view the source](https://github.com/schneiderfelipe/HTM.jl) and let me know
what you think.
Please help me improve it by
[sharing your feedback](https://github.com/schneiderfelipe/HTM.jl/issues).
Your contributions and bug reports are welcome on GitHub. üôè
